{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'vlkt'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n vlkt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from hico_text import hico_text_label\n",
    "​\n",
    "hico2coco = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13,\n",
    "                        14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
    "                        24, 25, 27, 28, 31, 32, 33, 34, 35, 36,\n",
    "                        37, 38, 39, 40, 41, 42, 43, 44, 46, 47,\n",
    "                        48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
    "                        58, 59, 60, 61, 62, 63, 64, 65, 67, 70,\n",
    "                        72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
    "                        82, 84, 85, 86, 87, 88, 89, 90)\n",
    "coco2hico = {v:i for i, v in enumerate(hico2coco)}\n",
    "​\n",
    "hoi_anno_path = '/mnt/HDD/hico_20160224_det/hico_list_hoi.txt'\n",
    "verb_anno_path = '/mnt/HDD/hico_20160224_det/hico_list_vb.txt'\n",
    "# obj_anno_path = '/mnt/HDD/hico_20160224_det/hico_list_obj.txt'\n",
    "​\n",
    "with open(hoi_anno_path, 'r') as f:\n",
    "    hoi_anno = f.readlines()\n",
    "with open(verb_anno_path, 'r') as f:\n",
    "    verb_anno = f.readlines()\n",
    "# with open(obj_anno_path, 'r') as f:\n",
    "#     obj_anno = f.readlines()\n",
    "​\n",
    "hoi_anno = [h.strip().split() for h in hoi_anno[2:]]\n",
    "verb_anno = [v.strip().split() for v in verb_anno[2:]]\n",
    "# obj_anno = [o.strip().split() for o in obj_anno[2:]]\n",
    "​\n",
    "verb_idx2class = {int(v[0]) : v[1] for v in verb_anno}\n",
    "obj_idx2class = {1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', \n",
    "                 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', \n",
    "                 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', \n",
    "                 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', \n",
    "                 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', \n",
    "                 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', \n",
    "                 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', \n",
    "                 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', \n",
    "                 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', \n",
    "                 90: 'toothbrush'}\n",
    "for k,v in obj_idx2class.items():\n",
    "    if len(v.split()) > 1:\n",
    "        obj_idx2class[k] = '_'.join(v.split())\n",
    "​\n",
    "verb_class2idx = {v:k for k,v in verb_idx2class.items()}\n",
    "obj_class2idx = {v:k for k,v in obj_idx2class.items()}\n",
    "​\n",
    "obj_in_verb = defaultdict(list)\n",
    "​\n",
    "for h in hoi_anno:\n",
    "    idx, obj, verb = h\n",
    "    verb_idx = verb_class2idx[verb]\n",
    "    obj_idx = obj_class2idx[obj]\n",
    "    obj_in_verb[verb_idx].append(obj_idx)\n",
    "    \n",
    "anno_file = '/mnt/HDD/hico_20160224_det/annotations/trainval_hico.json'\n",
    "# anno_file = '/mnt/HDD/hico_20160224_det/annotations/trainval_hico_diffusion_replace.json'\n",
    "# anno_file = '/mnt/HDD/hico_20160224_det/annotations/test_hico.json'\n",
    "​\n",
    "with open(anno_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "    \n",
    "root_path = '/mnt/HDD/hico_20160224_det/images/train2015'\n",
    "# root_path = '/mnt/HDD/hico_20160224_det/images/test2015'\n",
    "idx = 28\n",
    "img_path = annotations[idx]['file_name']\n",
    "img = cv2.imread(os.path.join(root_path,img_path))\n",
    "ori_img = img.copy()\n",
    "print(img_path)\n",
    "\n",
    "results = []\n",
    "for k, anno in enumerate(annotations[idx]['hoi_annotation']):\n",
    "    sub_id = anno['subject_id']\n",
    "    obj_id = anno['object_id']\n",
    "    sub_info = annotations[idx]['annotations'][sub_id]\n",
    "    obj_info = annotations[idx]['annotations'][obj_id]\n",
    "    \n",
    "    sub_category_id = sub_info['category_id']\n",
    "    obj_category_id = obj_info['category_id']\n",
    "    \n",
    "    sub_category = obj_idx2class[sub_category_id]\n",
    "    obj_category = obj_idx2class[obj_category_id]\n",
    "    \n",
    "    sub_bbox = sub_info['bbox']\n",
    "    obj_bbox = obj_info['bbox']\n",
    "    \n",
    "    sub_center = ((sub_bbox[0] + sub_bbox[2])//2, (sub_bbox[1] + sub_bbox[3])//2)\n",
    "    obj_center = ((obj_bbox[0] + obj_bbox[2])//2, (obj_bbox[1] + obj_bbox[3])//2)\n",
    "    \n",
    "    verb_category = verb_idx2class[anno['category_id']]\n",
    "    # print(anno['hoi_category_id'])\n",
    "    \n",
    "    cv2.rectangle(img, sub_bbox[:2], sub_bbox[2:], (0,255,0), 3)\n",
    "    cv2.rectangle(img, obj_bbox[:2], obj_bbox[2:], (255,0,0), 3)\n",
    "    cv2.line(img, sub_center, obj_center, (0,0,255), thickness=3)\n",
    "    \n",
    "    verb_loc = [(sub_center[0] + obj_center[0])//2, (sub_center[1] + obj_center[1])//2]\n",
    "    verb_loc[1] += k*20\n",
    "    cv2.putText(img, sub_category, sub_bbox[:2], cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, obj_category, obj_bbox[:2], cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, verb_category, verb_loc, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    result_dict = {}\n",
    "    result_dict['verb'] = verb_category\n",
    "    result_dict['object'] = obj_category\n",
    "    result_dict['sub_bbox'] = sub_bbox\n",
    "    result_dict['obj_bbox'] = obj_bbox\n",
    "    \n",
    "    results.append(result_dict)\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axes[0].imshow(ori_img[...,::-1])\n",
    "axes[0].set_title('Image')\n",
    "axes[0].axis('off')\n",
    "​\n",
    "axes[1].imshow(img[...,::-1])\n",
    "axes[1].set_title('GT')\n",
    "axes[1].axis('off')\n",
    "​\n",
    "# plt.show()\n",
    "​\n",
    "verb_idx=verb_class2idx[results[0]['verb']]\n",
    "print(results[0]['verb'])\n",
    "print([obj_idx2class[idx] for idx in obj_in_verb[verb_idx]])\n",
    "print([hico_text_label[(verb_idx-1, coco2hico[idx])] for idx in obj_in_verb[verb_idx]])\n",
    "​\n",
    "data = 'train'\n",
    "​\n",
    "if data == 'train':\n",
    "​\n",
    "    # anno_file = '/mnt/HDD/hico_20160224_det/annotations/trainval_hico.json'\n",
    "    anno_file = '/mnt/HDD/hico_20160224_det/annotations/trainval_hico_diffusion_replace.json'\n",
    "​\n",
    "    with open(anno_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "​\n",
    "    annotations = annotations[37633:]\n",
    "    \n",
    "    num_of_obj = defaultdict(int)\n",
    "    num_of_verb = defaultdict(int)\n",
    "    num_of_hoi = defaultdict(int)\n",
    "    hoi2verbobj = {}\n",
    "    max_verb = 0\n",
    "    for idx, anno in enumerate(annotations):\n",
    "        for ins in anno['annotations']:\n",
    "            obj_category_id = ins['category_id']\n",
    "            num_of_obj[obj_category_id] += 1\n",
    "​\n",
    "        for ins in anno['hoi_annotation']:\n",
    "            verb_category_id = ins['category_id'] # 1~117\n",
    "            hoi_category_id = ins['hoi_category_id'] # 1~600\n",
    "            \n",
    "            if hoi_category_id == 26:\n",
    "                print('this')\n",
    "                pass\n",
    "            if hoi_category_id == 130:\n",
    "                print('this')\n",
    "                pass\n",
    "            num_of_verb[verb_category_id] += 1\n",
    "            num_of_hoi[hoi_category_id] += 1\n",
    "                \n",
    "            sub_id = ins['subject_id']\n",
    "            obj_id = ins['object_id']\n",
    "            \n",
    "            hoi2verbobj[hoi_category_id] = (verb_category_id, anno['annotations'][obj_id]['category_id'])\n",
    "else:        \n",
    "    anno_file = '/mnt/HDD/hico_20160224_det/annotations/test_hico.json'\n",
    "​\n",
    "    with open(anno_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "​\n",
    "    num_of_obj = defaultdict(int)\n",
    "    num_of_verb = defaultdict(int)\n",
    "    num_of_hoi = defaultdict(int)\n",
    "    hoi2verbobj = {}\n",
    "​\n",
    "    hico_key2idx = {k:i for i, k in enumerate(list(hico_text_label.keys()))}\n",
    "​\n",
    "    for anno in annotations:\n",
    "        for ins in anno['annotations']:\n",
    "            obj_category_id = ins['category_id']\n",
    "            num_of_obj[obj_category_id] += 1\n",
    "​\n",
    "        for ins in anno['hoi_annotation']:\n",
    "            verb_category_id = ins['category_id'] # 1~117\n",
    "            num_of_verb[verb_category_id] += 1            \n",
    "            obj_id = ins['object_id']\n",
    "            obj_cat_id = anno['annotations'][obj_id]['category_id']\n",
    "            \n",
    "            hoi_category_id = hico_key2idx[(verb_category_id-1, coco2hico[obj_cat_id])]\n",
    "​\n",
    "            num_of_hoi[hoi_category_id] += 1\n",
    "​\n",
    "            hoi2verbobj[hoi_category_id] = (verb_category_id, obj_cat_id)\n",
    "            \n",
    "​\n",
    "new_obj_dict = {}\n",
    "for k,v in num_of_obj.items():\n",
    "    new_obj_dict[obj_idx2class[k]] = v\n",
    "​\n",
    "new_verb_dict = {}\n",
    "for k,v in num_of_verb.items():\n",
    "    new_verb_dict[verb_idx2class[k]] = v\n",
    "​\n",
    "new_hoi_dict = {}\n",
    "aa = []\n",
    "for k,v in num_of_hoi.items():\n",
    "    verb_category_id, obj_category_id = hoi2verbobj[k]\n",
    "    hoi_name = verb_idx2class[verb_category_id] + '_' + obj_idx2class[obj_category_id]\n",
    "    aa.append(hoi_name)\n",
    "    new_hoi_dict[hoi_name] = v\n",
    "    \n",
    "sorted_obj_dict = sorted(new_obj_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "sorted_verb_dict = sorted(new_verb_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "sorted_hoi_dict = sorted(new_hoi_dict.items(), key = lambda item: item[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the number of entries in the dataset\n",
    "print(\"Number of entries in the dataset:\", len(hico_dataset))\n",
    "\n",
    "# Access a specific entry\n",
    "entry = hico_dataset[0]  # Get the first entry, for example\n",
    "\n",
    "# Print out details of the entry to understand its structure\n",
    "print(json.dumps(entry, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deformable_detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
